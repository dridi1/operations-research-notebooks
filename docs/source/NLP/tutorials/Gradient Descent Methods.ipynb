{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Gradient Descent Methods\n",
    "## Introduction\n",
    "Gradient Descent Methods constitue a large family of heuristic methods based on the gradient definitions presented in the set up of unconstrained NLP. Gradient descent  methods are\n",
    "useful to find critical points and test whether they are global minimum (for minimisation problems) or global maximum (for maximisation problems).\n",
    "\n",
    "Basically, they consist of two types functions: \n",
    "\n",
    "- **search functions**: to find points where the gradient is zero or close to zero, i.e. functions to find critical points. \n",
    "- **test functions**: to verify whether the critical point is a global or local maximum or minimum.\n",
    "\n",
    "The different implementations have different performance trade-offs depending on the characteristics of the optimisation problem.\n",
    "In this notebook, we are going to cover two different methods, the simple gradient descent method and the stochastic gradient descent, with applications in machine learning.\n",
    "\n",
    "## Simple Gradient descent\n",
    "In the Simple gradient descent method, the algorithm starts at an initial point, calculates the gradient, and if its different than zero, it looks for the next point to test *in the direction opposite to the gradient*. Recall that, at any given point $x^*$ the gradient of the objective function $\\nabla f(x*)$ represents a vector tangent to $f(x*)$. This tangent vector represents the direction of the maximum change of x towards infinity in the n-dimensional space. Therefore, the algorithm continues the search in the opposite direction to this vector, assuming that this will provide the maximum change of the function towards its minimum value.\n",
    "With this, the Simple Gradient descent method can be defined as:\n",
    "\n",
    "**Start**\n",
    "\n",
    "- Choose an acceptable error $\\epsilon$\n",
    "- Choose a starting point $x'$\n",
    "\n",
    "**Iterate**\n",
    "\n",
    "- Calculate $\\nabla f(x')$\n",
    "- If $\\left|\\nabla f(x')\\right|\\leq \\epsilon$ then exit with x‚Ä≤ as the solution, else\n",
    "- Set $x''=ùë•'-t¬∑\\nabla f(x') \\quad t \\geq 0, t \\in \\mathbb{R}$ and iterate again. \n",
    "\n",
    "Note that since t is a positive value and  $\\left|\\nabla f(x')\\right|$ is a vector, we are changing the value of x in the direction of the vector. The change is proportional to t, which can be a fixed parameter or a calculated parameter depending on the implementation. \n",
    "One implementation alternative is to use a one-dimensional search (e.g using a bisection algorithm) to find $ùë°*$ such that $f(x'')$ is a local minimum. Note that since both $x'$ and $\\left|\\nabla f(x')\\right|$ are vectors, the only unknown is $t$, and this bisection is a reduction of the multi-dimensional minimisation problem to a one-dimensional minimisation problem.\n",
    "\n",
    "\n",
    "## Stochastic Gradient Descent (SGD)\n",
    "The stochastic gradient descent method can be applied in problems where the gradient of the objective function can be estimated from a subset of the parameters needed to compute the closed form of the gradient. \n",
    "The stochastic gradient descent is one of the fundamental optimization methods used in machine learning and given its importance, we will illustrate some outstanding applications of this method in the field of machine learaning the of this method using in the quadratic optimization examples.\n",
    "Let us consider the following objective function:\n",
    "\n",
    "$\\min  R_n(\\theta) = \\frac{1}{1}\\sum_{t=1}^{n}{L_i(\\theta)}$\n",
    "\n",
    "The stochastic gradient descent method is defined as: \n",
    "\n",
    "**Start**\n",
    "\n",
    "- Choose an acceptable error $\\epsilon$\n",
    "\n",
    "- Choose an starting point $\\theta$ (e.g $\\theta=0$)\n",
    "\n",
    "- Choose a learning factor for each iteration k $\\zeta_k$\n",
    " \n",
    "**Iterate**\n",
    "\n",
    "- select a random value $t*$\n",
    "\n",
    "- Calculate the gradient of $\\nabla L_{t*}(\\theta_k)$\n",
    "\n",
    "- Update $theta_k$ in the direction contrary to the gradient at $t*$: $\\theta_{k+1} = \\theta_{k} - \\zeta_k¬∑\\nabla L_{t*}(\\theta_k)$\n",
    "   \n",
    "- Repeat until the difference between two consecutive estimations is sufficiently small, or until the maximum number of iterations is reached.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}